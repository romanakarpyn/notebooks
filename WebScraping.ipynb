{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e0c3851-8842-4392-8e64-7339f36e3791",
   "metadata": {},
   "source": [
    "## Web scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f53d16-0685-44f4-9535-aa88326eccb3",
   "metadata": {},
   "source": [
    "Scrape bank's contact informations and write them to a txt file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2381008d-cdd4-4b80-8192-ef1be14c3f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "import webbrowser\n",
    "import string\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1c26e5-dd12-4c7a-b892-b64389ad6714",
   "metadata": {},
   "source": [
    "Check whether the website supports web scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9cae9c6-fb6c-478e-a9e2-000c48961102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webbrowser.open('http://bankinfouk.com/robots.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fbed16-cdde-428c-91f3-03a04b71570d",
   "metadata": {},
   "source": [
    "#### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b19e0ce6-4550-4397-82a1-1c2918557139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "page_num = 1\n",
    "url = \"http://bankinfouk.com/banks/contacts/page:1\"\n",
    "\n",
    "while page_num <= 5:\n",
    "    url = url[:len(url) - 1] + str(page_num)  # Modify existing url to move to the next page on website\n",
    "    response = requests.get(url)\n",
    "    # print(response.status_code)\n",
    "    \n",
    "    soup_obj = bs4.BeautifulSoup(response.content, \"html.parser\")\n",
    "    \n",
    "    # Scrape multiple classes and write data into Banks_data.txt's file\n",
    "    for chunk in soup_obj.find_all('div', {'class': ['result-title', 'description']}):\n",
    "        with open(str(Path.cwd()) + '/' + 'banks_data.txt', 'a') as file:\n",
    "            # print(chunk.text.strip(string.whitespace)) \n",
    "            file.write(chunk.text)\n",
    "    page_num += 1  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc62a2d-51d8-4039-9337-2d5d0bb789d2",
   "metadata": {},
   "source": [
    "## Simple financial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cde1372-e4c0-4d1b-99b0-3415d7908345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webbrowser.open('https://www.msn.com/robots.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06467a05-7163-4c09-9d66-c6186175ce3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOW</th>\n",
       "      <th>S&amp;P 500</th>\n",
       "      <th>NASDAQ</th>\n",
       "      <th>IBOVESPA</th>\n",
       "      <th>EURO STOXX 50</th>\n",
       "      <th>DAX</th>\n",
       "      <th>CAC 40</th>\n",
       "      <th>IBEX 35</th>\n",
       "      <th>Nikkei 225</th>\n",
       "      <th>Shanghai Composite</th>\n",
       "      <th>Hang Seng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <td>32,899.70</td>\n",
       "      <td>4,108.54</td>\n",
       "      <td>12,012.73</td>\n",
       "      <td>111,102.32</td>\n",
       "      <td>3,783.66</td>\n",
       "      <td>14,460.09</td>\n",
       "      <td>6,485.30</td>\n",
       "      <td>8,724.80</td>\n",
       "      <td>27,761.57</td>\n",
       "      <td>3,195.46</td>\n",
       "      <td>21,082.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Variation</th>\n",
       "      <td>-1.05%</td>\n",
       "      <td>-1.63%</td>\n",
       "      <td>-2.47%</td>\n",
       "      <td>-1.15%</td>\n",
       "      <td>-0.30%</td>\n",
       "      <td>-0.17%</td>\n",
       "      <td>-0.23%</td>\n",
       "      <td>-0.22%</td>\n",
       "      <td>+1.27%</td>\n",
       "      <td>+0.42%</td>\n",
       "      <td>-1.00%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 DOW   S&P 500     NASDAQ    IBOVESPA EURO STOXX 50  \\\n",
       "Price      32,899.70  4,108.54  12,012.73  111,102.32      3,783.66   \n",
       "Variation     -1.05%    -1.63%     -2.47%      -1.15%        -0.30%   \n",
       "\n",
       "                 DAX    CAC 40  IBEX 35  Nikkei 225 Shanghai Composite  \\\n",
       "Price      14,460.09  6,485.30  8,724.80  27,761.57           3,195.46   \n",
       "Variation     -0.17%    -0.23%    -0.22%     +1.27%             +0.42%   \n",
       "\n",
       "           Hang Seng  \n",
       "Price      21,082.13  \n",
       "Variation     -1.00%  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_2 = \"https://www.msn.com/en-gb/money/markets\"\n",
    "\n",
    "\n",
    "response_2 = requests.get(url_2)\n",
    "soup = bs4.BeautifulSoup(response_2.content, 'html.parser')\n",
    "data = soup.find_all(\"div\", class_ = \"secondaryIndexTile\")\n",
    "\n",
    "\n",
    "\n",
    "dic_data = dict()\n",
    "for element in data:\n",
    "    title = element.find(\"div\", class_ =\"title\")\n",
    "    price = element.find(\"div\", class_ = \"price\")\n",
    "    variation = element.find(\"div\" , class_ = \"chp\")\n",
    "    dic_data[title.text] = [price.text, variation.text]\n",
    "\n",
    "#view the data in table format \n",
    "data = dic_data.copy()\n",
    "import pandas as pd\n",
    "data = pd.DataFrame(data, index = ['Price', 'Variation'])\n",
    "data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
