{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e0c3851-8842-4392-8e64-7339f36e3791",
   "metadata": {},
   "source": [
    "## Web scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f53d16-0685-44f4-9535-aa88326eccb3",
   "metadata": {},
   "source": [
    "Scrape bank's contact informations and write them to a txt file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2381008d-cdd4-4b80-8192-ef1be14c3f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "import webbrowser\n",
    "import string\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1c26e5-dd12-4c7a-b892-b64389ad6714",
   "metadata": {},
   "source": [
    "Check whether the website supports web scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9cae9c6-fb6c-478e-a9e2-000c48961102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webbrowser.open('http://bankinfouk.com/robots.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fbed16-cdde-428c-91f3-03a04b71570d",
   "metadata": {},
   "source": [
    "#### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b19e0ce6-4550-4397-82a1-1c2918557139",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data\n",
    "page_num = 1\n",
    "url = \"http://bankinfouk.com/banks/contacts/page:1\"\n",
    "\n",
    "while page_num <= 5:\n",
    "    url = url[:len(url)-1]+str(page_num) #modify existing url to move to the next page on website\n",
    "    response = requests.get(url)\n",
    "    #print(response.status_code)\n",
    "    \n",
    "    soup_obj= bs4.BeautifulSoup(response.content, \"html.parser\")\n",
    "    \n",
    "    #scrape multiple classes and write data into Banks_data.txt's file\n",
    "    for chunk in soup_obj.find_all('div', {'class' : ['result-title', 'description']}):\n",
    "        with open(str(Path.cwd())+'/'+'banks_data.txt', 'a') as file:\n",
    "            #print(chunk.text.strip(string.whitespace)) \n",
    "            file.write(chunk.text)\n",
    "    page_num += 1  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc62a2d-51d8-4039-9337-2d5d0bb789d2",
   "metadata": {},
   "source": [
    "## Simple financial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cde1372-e4c0-4d1b-99b0-3415d7908345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webbrowser.open('https://www.msn.com/robots.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06467a05-7163-4c09-9d66-c6186175ce3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOW</th>\n",
       "      <th>S&amp;P 500</th>\n",
       "      <th>NASDAQ</th>\n",
       "      <th>IBOVESPA</th>\n",
       "      <th>EURO STOXX 50</th>\n",
       "      <th>DAX</th>\n",
       "      <th>CAC 40</th>\n",
       "      <th>IBEX 35</th>\n",
       "      <th>Nikkei 225</th>\n",
       "      <th>Shanghai Composite</th>\n",
       "      <th>Hang Seng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <td>34,451.23</td>\n",
       "      <td>4,392.59</td>\n",
       "      <td>13,351.08</td>\n",
       "      <td>116,181.61</td>\n",
       "      <td>3,848.68</td>\n",
       "      <td>14,163.85</td>\n",
       "      <td>6,589.35</td>\n",
       "      <td>8,699.00</td>\n",
       "      <td>27,093.19</td>\n",
       "      <td>3,211.24</td>\n",
       "      <td>21,518.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Variation</th>\n",
       "      <td>-0.33%</td>\n",
       "      <td>-1.21%</td>\n",
       "      <td>-2.14%</td>\n",
       "      <td>-0.51%</td>\n",
       "      <td>+0.54%</td>\n",
       "      <td>+0.62%</td>\n",
       "      <td>+0.72%</td>\n",
       "      <td>+0.94%</td>\n",
       "      <td>-0.29%</td>\n",
       "      <td>-0.45%</td>\n",
       "      <td>+0.67%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 DOW   S&P 500     NASDAQ    IBOVESPA EURO STOXX 50  \\\n",
       "Price      34,451.23  4,392.59  13,351.08  116,181.61      3,848.68   \n",
       "Variation     -0.33%    -1.21%     -2.14%      -0.51%        +0.54%   \n",
       "\n",
       "                 DAX    CAC 40  IBEX 35  Nikkei 225 Shanghai Composite  \\\n",
       "Price      14,163.85  6,589.35  8,699.00  27,093.19           3,211.24   \n",
       "Variation     +0.62%    +0.72%    +0.94%     -0.29%             -0.45%   \n",
       "\n",
       "           Hang Seng  \n",
       "Price      21,518.08  \n",
       "Variation     +0.67%  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_2 = \"https://www.msn.com/en-gb/money/markets\"\n",
    "\n",
    "\n",
    "response_2 = requests.get(url_2)\n",
    "soup = bs4.BeautifulSoup(response_2.content, 'html.parser')\n",
    "data = soup.find_all(\"div\", class_ = \"secondaryIndexTile\")\n",
    "\n",
    "\n",
    "\n",
    "dic_data = dict()\n",
    "for element in data:\n",
    "    title = element.find(\"div\", class_ =\"title\")\n",
    "    price = element.find(\"div\", class_ = \"price\")\n",
    "    variation = element.find(\"div\" , class_ = \"chp\")\n",
    "    dic_data[title.text] = [price.text, variation.text]\n",
    "\n",
    "#view the data in table format \n",
    "data = dic_data.copy()\n",
    "import pandas as pd\n",
    "data = pd.DataFrame(data, index = ['Price', 'Variation'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d75368-d65b-4619-a42f-999adf60f938",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a286233-0064-4215-a897-de5275aaba17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
